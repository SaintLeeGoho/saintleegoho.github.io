<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Spark框架入门 | GohoLee</title>
    <meta name="generator" content="VuePress 1.9.7">
    <link rel="icon" href="/favicon.ico">
    <meta name="description" content="blog by GohoLee">
    <meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no">
    
    <link rel="preload" href="/assets/css/0.styles.15bca8c4.css" as="style"><link rel="preload" href="/assets/js/app.4c955a77.js" as="script"><link rel="preload" href="/assets/js/4.1f64e010.js" as="script"><link rel="preload" href="/assets/js/1.2b09ee83.js" as="script"><link rel="preload" href="/assets/js/9.30f2afa9.js" as="script"><link rel="prefetch" href="/assets/js/10.08341258.js"><link rel="prefetch" href="/assets/js/11.44b1e064.js"><link rel="prefetch" href="/assets/js/12.46caf217.js"><link rel="prefetch" href="/assets/js/13.2a24eef2.js"><link rel="prefetch" href="/assets/js/14.18303fff.js"><link rel="prefetch" href="/assets/js/15.eb41772c.js"><link rel="prefetch" href="/assets/js/16.dbac35fb.js"><link rel="prefetch" href="/assets/js/17.3881a037.js"><link rel="prefetch" href="/assets/js/18.a6042dc9.js"><link rel="prefetch" href="/assets/js/19.f1b368c9.js"><link rel="prefetch" href="/assets/js/20.305a152a.js"><link rel="prefetch" href="/assets/js/21.f54a0bb0.js"><link rel="prefetch" href="/assets/js/22.e026b642.js"><link rel="prefetch" href="/assets/js/3.c860fb87.js"><link rel="prefetch" href="/assets/js/5.7d1d4fdd.js"><link rel="prefetch" href="/assets/js/6.6b47eb9b.js"><link rel="prefetch" href="/assets/js/7.1e7dcb9a.js"><link rel="prefetch" href="/assets/js/8.ff9809b2.js">
    <link rel="stylesheet" href="/assets/css/0.styles.15bca8c4.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar" data-v-7dd95ae2><div data-v-7dd95ae2><div class="password-shadow password-wrapper-out" style="display:none;" data-v-59e6cb88 data-v-7dd95ae2 data-v-7dd95ae2><h3 class="title" data-v-59e6cb88>GohoLee</h3> <p class="description" data-v-59e6cb88>blog by GohoLee</p> <label id="box" class="inputBox" data-v-59e6cb88><input type="password" value="" data-v-59e6cb88> <span data-v-59e6cb88>Konck! Knock!</span> <button data-v-59e6cb88>OK</button></label> <div class="footer" data-v-59e6cb88><span data-v-59e6cb88><i class="iconfont reco-theme" data-v-59e6cb88></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-59e6cb88>vuePress-theme-reco</a></span> <span data-v-59e6cb88><i class="iconfont reco-copyright" data-v-59e6cb88></i> <a data-v-59e6cb88><span data-v-59e6cb88>GohoLee</span>
          
        <span data-v-59e6cb88>2017 - </span>
        2023
      </a></span></div></div> <div class="hide" data-v-7dd95ae2><header class="navbar" data-v-7dd95ae2><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/avatar.png" alt="GohoLee" class="logo"> <span class="site-name">GohoLee</span></a> <div class="links"><div class="color-picker"><a class="color-button"><i class="iconfont reco-color"></i></a> <div class="color-picker-menu" style="display:none;"><div class="mode-options"><h4 class="title">Choose mode</h4> <ul class="color-mode-options"><li class="dark">dark</li><li class="auto active">auto</li><li class="light">light</li></ul></div></div></div> <div class="search-box"><i class="iconfont reco-search"></i> <input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link"><i class="iconfont reco-home"></i>
  主页Home
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-category"></i>
      分类Category
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/Big Data/" class="nav-link"><i class="undefined"></i>
  Big Data
</a></li><li class="dropdown-item"><!----> <a href="/categories/前端基础/" class="nav-link"><i class="undefined"></i>
  前端基础
</a></li></ul></div></div><div class="nav-item"><a href="/tag/" class="nav-link"><i class="iconfont reco-tag"></i>
  标签Tag
</a></div><div class="nav-item"><a href="/timeline/" class="nav-link"><i class="iconfont reco-date"></i>
  时间线TimeLine
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-message"></i>
      文档Docs
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/docs/Saint/" class="nav-link"><i class="undefined"></i>
  关于博主
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-message"></i>
      联系Contact
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/saintleegoho" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-github"></i>
  GitHub
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask" data-v-7dd95ae2></div> <aside class="sidebar" data-v-7dd95ae2><div class="personal-info-wrapper" data-v-1fad0c41 data-v-7dd95ae2><img src="/avatar.png" alt="author-avatar" class="personal-img" data-v-1fad0c41> <h3 class="name" data-v-1fad0c41>
    GohoLee
  </h3> <div class="num" data-v-1fad0c41><div data-v-1fad0c41><h3 data-v-1fad0c41>12</h3> <h6 data-v-1fad0c41>文章</h6></div> <div data-v-1fad0c41><h3 data-v-1fad0c41>11</h3> <h6 data-v-1fad0c41>标签</h6></div></div> <ul class="social-links" data-v-1fad0c41></ul> <hr data-v-1fad0c41></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link"><i class="iconfont reco-home"></i>
  主页Home
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-category"></i>
      分类Category
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/Big Data/" class="nav-link"><i class="undefined"></i>
  Big Data
</a></li><li class="dropdown-item"><!----> <a href="/categories/前端基础/" class="nav-link"><i class="undefined"></i>
  前端基础
</a></li></ul></div></div><div class="nav-item"><a href="/tag/" class="nav-link"><i class="iconfont reco-tag"></i>
  标签Tag
</a></div><div class="nav-item"><a href="/timeline/" class="nav-link"><i class="iconfont reco-date"></i>
  时间线TimeLine
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-message"></i>
      文档Docs
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/docs/Saint/" class="nav-link"><i class="undefined"></i>
  关于博主
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-message"></i>
      联系Contact
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/saintleegoho" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-github"></i>
  GitHub
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav> <!----> </aside> <div class="password-shadow password-wrapper-in" style="display:none;" data-v-59e6cb88 data-v-7dd95ae2><h3 class="title" data-v-59e6cb88>Spark框架入门</h3> <!----> <label id="box" class="inputBox" data-v-59e6cb88><input type="password" value="" data-v-59e6cb88> <span data-v-59e6cb88>Konck! Knock!</span> <button data-v-59e6cb88>OK</button></label> <div class="footer" data-v-59e6cb88><span data-v-59e6cb88><i class="iconfont reco-theme" data-v-59e6cb88></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-59e6cb88>vuePress-theme-reco</a></span> <span data-v-59e6cb88><i class="iconfont reco-copyright" data-v-59e6cb88></i> <a data-v-59e6cb88><span data-v-59e6cb88>GohoLee</span>
          
        <span data-v-59e6cb88>2017 - </span>
        2023
      </a></span></div></div> <div data-v-7dd95ae2><div data-v-7dd95ae2><main class="page"><section style="display:;"><div class="page-title"><h1 class="title">Spark框架入门</h1> <div data-v-8a445198><i class="iconfont reco-account" data-v-8a445198><span data-v-8a445198>GohoLee</span></i> <i class="iconfont reco-date" data-v-8a445198><span data-v-8a445198>7/21/2023</span></i> <!----> <i class="tags iconfont reco-tag" data-v-8a445198><span class="tag-item" data-v-8a445198>Spark</span></i></div></div> <div class="theme-reco-content content__default"><h1 id="spark基础解析"><a href="#spark基础解析" class="header-anchor">#</a> Spark基础解析</h1> <h2 id="第1章-spark概述"><a href="#第1章-spark概述" class="header-anchor">#</a> 第1章 Spark概述</h2> <h3 id="_1-1-什么是spark"><a href="#_1-1-什么是spark" class="header-anchor">#</a> 1.1 什么是Spark</h3> <ol><li><p>定义</p> <p>Spark是一种基于内存的快速、痛殴公用、可扩展的大数据分析引擎。</p></li> <li><p>历史</p> <p>2009年诞生于加州大学伯克利分校AMPLab，项目采用Scala编写。</p> <p>2010年开源。</p> <p>2013年6月成为Apache孵化项目。</p> <p>2014年2月成为Apache顶级项目。</p></li></ol> <h3 id="_1-2-spark内置模块"><a href="#_1-2-spark内置模块" class="header-anchor">#</a> 1.2 Spark内置模块</h3> <p><img src="/assets/img/Spark内置模块.99b07d15.png" alt="img"></p> <ol><li><p>Spark Core：实现了Spark的基本功能，包含任务调度、内存管理、错误恢复、与存储系统交互等模块。Spark Core中还包含了对弹性分布式数据集(Resilient Distributed DataSet，简称RDD)的API定义。</p></li> <li><p>Spark SQL：是Spark用来操作结构化数据的程序包。通过Spark SQL，我们可以使用SQL或者Apache Hive版本的SQL方言(HQL)来查询数据。Spark SQL支持多种数据源，比如Hive表、Parquet以及JSON等。</p></li> <li><p>Spark Streaming：是Spark提供的对实时数据进行流式计算的组件。提供了用来操作数据流的API，并且与Spark Core中的 RDD API高度对应。</p></li> <li><p>Spark MLlib：提供常见的机器学习(ML)功能的程序库。包括分类、回归、聚类、协同过滤等，还提供了模型评估、数据 导入等额外的支持功能。</p></li> <li><p>集群管理器：Spark 设计为可以高效地在一个计算节点到数千个计算节点之间伸缩计 算。为了实现这样的要求，同时获得最大灵活性，Spark支持在各种集群管理器(Cluster Manager)上运行，包括Hadoop YARN、Apache Mesos，以及Spark自带的一个简易调度 器，叫作独立调度器。</p></li></ol> <p>Spark得到了众多大数据公司的支持，这些公司包括Hortonworks、IBM、Intel、Cloudera、MapR、Pivotal、百度、阿里、腾讯、京东、携程、优酷土豆。当前百度的Spark已应用于大搜索、直达号、百度大数据等业务；阿里利用GraphX构建了大规模的图计算和图挖掘系统，实现了很多生产系统的推荐算法；腾讯Spark集群达到8000台的规模，是当前已知的世界上最大的Spark集群。</p> <h3 id="_1-3-spark特点"><a href="#_1-3-spark特点" class="header-anchor">#</a> 1.3 Spark特点</h3> <ol><li>快：与Hadoop的MapReduce相比，Spark基于内存的运算要快100倍以上，基于硬盘的运算也要快10倍以上。Spark实现了高效的DAG执行引擎，可以通过基于内存来高效处理数据流。计算的中间结果是存在于内存中的。</li> <li>易用：Spark支持Java、Python和Scala的API，还支持超过80种高级算法，使用户可以快速构建不同的应用。而且Spak支持交互式的Python和Scala的Shell，可以非常方便地在这些Shell中使用Spark集群来验证解决问题的方法。</li> <li>通用：Spatk提供了统一的解决方案。Spark可以用于批处理、交互式查询（SparkSQL）、实时流处理（Spark Streaming）、机器学习（Spark MLlib）和图计算（GraphX）。这些不同类型的处理都可以在同一个应 用中无缝使用。减少了开发和维护的人力成本和部署平台的物力成本。</li> <li>兼容性：Spark可以非常方便地与其他的开源产品进行融合。比如，Spak可以使用Hadoop的YARN和Apache Mesos作为它的资源管理和调度器，并且可以处理所有Hadoop支持的数据，包括HDFS、HBase等。这对于已经部署Hadoop集群的用户特别重要，因为不需要做任何数据迁移就可以使用Spark的强大处理能力。</li></ol> <h2 id="第2章-spark运行模式"><a href="#第2章-spark运行模式" class="header-anchor">#</a> 第2章 Spark运行模式</h2> <h3 id="_2-1-spark安装地址"><a href="#_2-1-spark安装地址" class="header-anchor">#</a> 2.1 Spark安装地址</h3> <p>1．官网地址</p> <p><a href="http://spark.apache.org/" target="_blank" rel="noopener noreferrer">http://spark.apache.org/<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>2．文档查看地址</p> <p><a href="https://spark.apache.org/docs/2.1.1/" target="_blank" rel="noopener noreferrer">https://spark.apache.org/docs/2.1.1/<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>3．下载地址</p> <p><a href="https://spark.apache.org/downloads.html" target="_blank" rel="noopener noreferrer">https://spark.apache.org/downloads.html<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <h3 id="_2-3-local模式"><a href="#_2-3-local模式" class="header-anchor">#</a> 2.3 Local模式</h3> <h4 id="_2-3-1-概述"><a href="#_2-3-1-概述" class="header-anchor">#</a> 2.3.1 概述</h4> <p>Local模式就是运行在一台计算机上的模式，通常就是用于在本机上练手和测试。它可以通过以下集中方式设置Master。</p> <ol><li>local：所有计算都运行在一个线程当中，没有任何并行计算，通常我们在本机执行一些测试代码，或者练手，就用这种模式，</li> <li>local［K］：指定使用几个线程来运行计算，比如local［4］就是运行4个Worker线程。通常我们的Cpu有几个Core，就指定几个线程，最大化利用Cpu的计算能力；</li> <li>local［＊］：这种模式直接帮你按照Cpu最多Cores来设置线程数了。</li></ol> <h4 id="_2-3-2-安装使用"><a href="#_2-3-2-安装使用" class="header-anchor">#</a> 2.3.2 安装使用</h4> <p>1）上传并解压spark安装包</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@hadoop01 sorfware<span class="token punctuation">]</span><span class="token comment"># tar -zxvf spark-2.1.1-bin-hadoop2.7.tgz -C /opt/module/</span>

<span class="token punctuation">[</span>root@hadoop01 module<span class="token punctuation">]</span><span class="token comment"># mv spark-2.1.1-bin-hadoop2.7 spark</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>2）官方求PI案例</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@hadoop01 spark<span class="token punctuation">]</span><span class="token comment"># bin/spark-submit \</span>
<span class="token parameter variable">--class</span> org.apache.spark.examples.SparkPi <span class="token punctuation">\</span>
--executor-memory 1G <span class="token punctuation">\</span>
--total-executor-cores <span class="token number">2</span> <span class="token punctuation">\</span>
./examples/jars/spark-examples_2.11-2.1.1.jar <span class="token punctuation">\</span>
<span class="token number">100</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>（1）基本语法</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code>bin/spark-submit <span class="token punctuation">\</span>
<span class="token parameter variable">--class</span> <span class="token operator">&lt;</span>main-class<span class="token operator">&gt;</span>
<span class="token parameter variable">--master</span> <span class="token operator">&lt;</span>master-url<span class="token operator">&gt;</span> <span class="token punctuation">\</span>
--deploy-mode <span class="token operator">&lt;</span>deploy-mode<span class="token operator">&gt;</span> <span class="token punctuation">\</span>
<span class="token parameter variable">--conf</span> <span class="token operator">&lt;</span>key<span class="token operator">&gt;=</span><span class="token operator">&lt;</span>value<span class="token operator">&gt;</span> <span class="token punctuation">\</span>
<span class="token punctuation">..</span>. <span class="token comment">## other options</span>
<span class="token operator">&lt;</span>application-jar<span class="token operator">&gt;</span> <span class="token punctuation">\</span>
<span class="token punctuation">[</span>application-arguments<span class="token punctuation">]</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><p>（2）参数说明：</p> <ol><li><p>--master 指定Master的地址，默认为Local</p></li> <li><p>--class: 你的应用的启动类 (如 org.apache.spark.examples.SparkPi)</p></li> <li><p>--deploy-mode: 是否发布你的驱动到worker节点(cluster) 或者作为一个本地客户端 (client) (default: client)*</p></li> <li><p>--conf: 任意的Spark配置属性， 格式key=value. 如果值包含空格，可以加引号“key=value”</p></li> <li><p>application-jar: 打包好的应用jar,包含依赖. 这个URL在集群中全局可见。 比如hdfs:// 共享存储系统， 如果是 file:// path， 那么所有的节点的path都包含同样的jar</p></li> <li><p>application-arguments: 传给main()方法的参数</p></li> <li><p>--executor-memory 1G 指定每个executor可用内存为1G</p></li> <li><p>--total-executor-cores 2 指定每个executor使用的cup核数为2个</p></li></ol> <p>3）结果展示</p> <p>该算法是利用蒙特·卡罗算法求PI</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>Pi is roughly 3.1414611141461113
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>4）准备文件</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@hadoop01 spark<span class="token punctuation">]</span><span class="token comment"># mkdir input</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>在input下创建3个文件1.txt和2.txt，并输入以下内容</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hello root
hello spark
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>5）启动spark-shell</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@hadoop01 spark<span class="token punctuation">]</span><span class="token comment"># bin/spark-shell</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><div class="language- line-numbers-mode"><pre class="language-text"><code>Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to &quot;WARN&quot;.
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
23/07/21 03:19:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/07/21 03:19:31 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
23/07/21 03:19:32 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
23/07/21 03:19:33 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
Spark context Web UI available at http://192.168.38.101:4040
Spark context available as 'sc' (master = local[*], app id = local-1689934765580).
Spark session available as 'spark'.
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 2.1.1
      /_/
         
Using Scala version 2.11.8 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_144)
Type in expressions to have them evaluated.
Type :help for more information.

scala&gt; 
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br></div></div><p>开启另一个CRD窗口</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@hadoop01 spark<span class="token punctuation">]</span><span class="token comment"># jps</span>
<span class="token number">3627</span> SparkSubmit
<span class="token number">4047</span> Jps
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>可登录hadoop01:4040查看程序运行</p> <p><img src="/assets/img/hadoop01的4040端口.ee0b799b.png" alt="image-20230721103617782"></p> <p>6）运行WordCount程序</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code>scala<span class="token operator">&gt;</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;input&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span><span class="token punctuation">.</span>collect
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><div class="language- line-numbers-mode"><pre class="language-text"><code>res0: Array[(String, Int)] = Array((spark,1), (hello,2), (root,1))
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>可登录hadoop01:4040查看程序运行</p> <p><img src="/assets/img/image-20230721110719846.19bec149.png" alt="image-20230721110719846"></p> <h4 id="_2-3-3-提交流程"><a href="#_2-3-3-提交流程" class="header-anchor">#</a> 2.3.3 提交流程</h4> <p>1）提交任务分析：</p> <p><img src="/assets/img/SparkLocal模式提交任务分析.fcab7bfd.png" alt="img"></p> <p>重要角色：</p> <p>Driver（驱动器）</p> <p>Spark的驱动器是执行开发程序中的main方法的进程。它负责开发人员编写的用来创建SparkContext、创建RDD，以及进行RDD的转化操作和行动操作代码的执行。如果你是用spark shell，那么当你启动Spark shell的时候，系统后台自启了一个Spark驱动器程序，就是在Spark shell中预加载的一个叫作 sc 的SparkContext对象。如果驱动器程序终止，那么Spark应用也就结束了。主要负责：</p> <p>1）把用户程序转为任务</p> <p>2）跟踪Executor的运行状况</p> <p>3）为执行器节点调度任务</p> <p>4）UI展示应用运行状况</p> <p>Executor（执行器）</p> <p>Spark Executor是一个工作进程，负责在 Spark 作业中运行任务，任务间相互独立。Spark 应用启动时，Executor节点被同时启动，并且始终伴随着整个 Spark 应用的生命周期而存在。如果有Executor节点发生了故障或崩溃，Spark 应用也可以继续执行，会将出错节点上的任务调度到其他Executor节点上继续运行。主要负责：</p> <p>1）负责运行组成 Spark 应用的任务，并将结果返回给驱动器进程；</p> <p>2）通过自身的块管理器（Block Manager）为用户程序中要求缓存的RDD提供内存式存储。RDD是直接缓存在Executor进程内的，因此任务可以在运行时充分利用缓存数据加速运算。</p> <h4 id="_2-3-4-数据流程"><a href="#_2-3-4-数据流程" class="header-anchor">#</a> 2.3.4 数据流程</h4> <p>textFile(&quot;input&quot;)：读取本地文件input文件夹数据；</p> <p>flatMap(_.split(&quot; &quot;))：压平操作，按照空格分割符将一行数据映射成一个个单词；</p> <p>map((_,1))：对每一个元素操作，将单词映射为元组；</p> <p>reduceByKey(_+_)：按照key将值进行聚合，相加；</p> <p>collect：将数据收集到Driver端展示。</p> <p><img src="/assets/img/WordCount案例分析.0d26cac0.png" alt="img"></p> <h3 id="_2-4-standalone模式"><a href="#_2-4-standalone模式" class="header-anchor">#</a> 2.4 Standalone模式</h3> <h4 id="_2-4-1-概述"><a href="#_2-4-1-概述" class="header-anchor">#</a> 2.4.1 概述</h4> <p>构建一个由Master+Slave构成的Spark集群，Spark运行在集群中。</p> <p><img src="/assets/img/Standalone运行模式介绍.ed80a148.png" alt="img"></p> <h4 id="_2-4-2-安装使用"><a href="#_2-4-2-安装使用" class="header-anchor">#</a> 2.4.2 安装使用</h4> <p>1）进入spark安装目录下的conf文件夹</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@hadoop01 module<span class="token punctuation">]</span><span class="token comment"># cd spark/conf/</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>2）修改配置文件名称</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@hadoop01 conf<span class="token punctuation">]</span><span class="token comment"># mv slaves.template slaves</span>
<span class="token punctuation">[</span>root@hadoop02 conf<span class="token punctuation">]</span><span class="token comment"># mv spark-env.sh.template spark-env.sh</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>3）修改slave文件，添加work节点：</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@hadoop01 conf<span class="token punctuation">]</span><span class="token comment"># vim slaves</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><div class="language- line-numbers-mode"><pre class="language-text"><code>hadoop01
hadoop02
hadoop03
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>4）修改spark-env.sh文件，添加如下配置：</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@hadoop01 conf<span class="token punctuation">]</span><span class="token comment"># vim spark-env.sh</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><div class="language-properties line-numbers-mode"><pre class="language-properties"><code><span class="token key attr-name">SPARK_MASTER_HOST</span><span class="token punctuation">=</span><span class="token value attr-value">hadoop01</span>
<span class="token key attr-name">SPARK_MASTER_PORT</span><span class="token punctuation">=</span><span class="token value attr-value">7077</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>5）分发spark包</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@hadoop01 module<span class="token punctuation">]</span><span class="token comment"># xsync spark/</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>6）启动</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@hadoop01 spark<span class="token punctuation">]</span><span class="token comment"># sbin/start-all.sh</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>此时hadoop01运行jps，会看到Worker和Master进程</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@hadoop01 spark<span class="token punctuation">]</span><span class="token comment"># jps</span>
<span class="token number">3330</span> Jps
<span class="token number">3238</span> Worker
<span class="token number">3163</span> Master
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>网页查看：hadoop01:8080</p> <p>注意：如果遇到 “JAVA_HOME not set” 异常，可以在sbin目录下的spark-config.sh 文件中加入如下配置：</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token builtin class-name">export</span> <span class="token assign-left variable">JAVA_HOME</span><span class="token operator">=</span>/opt/module/jdk1.8.0_144
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>7）官方求PI案例</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@hadoop01 spark<span class="token punctuation">]</span><span class="token comment"># bin/spark-submit \</span>
<span class="token parameter variable">--class</span> org.apache.spark.examples.SparkPi <span class="token punctuation">\</span>
<span class="token parameter variable">--master</span> spark://hadoop01:7077 <span class="token punctuation">\</span>
--executor-memory 1G <span class="token punctuation">\</span>
--total-executor-cores <span class="token number">2</span> <span class="token punctuation">\</span>
./examples/jars/spark-examples_2.11-2.1.1.jar <span class="token punctuation">\</span>
<span class="token number">100</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><div class="language- line-numbers-mode"><pre class="language-text"><code>Pi is roughly 3.1412747141274715
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>8）启动spark shell</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code>/opt/module/spark/bin/spark-shell <span class="token punctuation">\</span>
<span class="token parameter variable">--master</span> spark://hadoop01:7077 <span class="token punctuation">\</span>
--executor-memory 1g <span class="token punctuation">\</span>
--total-executor-cores <span class="token number">2</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>参数：--master spark://hadoop01:7077指定要连接的集群的master</p> <p>执行WordCount程序</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code>scala<span class="token operator">&gt;</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;input&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span><span class="token punctuation">.</span>collect
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><div class="language-scala line-numbers-mode"><pre class="language-scala"><code>res1<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token punctuation">(</span>hello<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>root<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>spark<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

scala<span class="token operator">&gt;</span> 
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><h4 id="_2-4-3-jobhistoryserver配置"><a href="#_2-4-3-jobhistoryserver配置" class="header-anchor">#</a> 2.4.3 JobHistoryServer配置</h4> <p>1）修改spark-default.conf.template名称</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@hadoop01 conf<span class="token punctuation">]</span><span class="token comment"># mv spark-defaults.conf.template spark-defaults.conf</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>2）修改spark-default.conf文件，开启Log：</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@hadoop01 conf<span class="token punctuation">]</span><span class="token comment"># vi spark-defaults.conf</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><div class="language- line-numbers-mode"><pre class="language-text"><code>spark.eventLog.enabled true
spark.eventLog.dir hdfs://hadoop01:9000/directory
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>注意：HDFS上的目录需要提前存在。</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@hadoop01 hadoop-2.7.2<span class="token punctuation">]</span>$ hadoop fs <span class="token parameter variable">-mkdir</span> <span class="token parameter variable">-p</span> /directory
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>3）修改spark-env.sh文件，添加如下配置：</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@hadoop01 conf<span class="token punctuation">]</span><span class="token comment"># vi spark-env.sh</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><div class="language-properties line-numbers-mode"><pre class="language-properties"><code><span class="token key attr-name">export</span> <span class="token value attr-value">SPARK_HISTORY_OPTS=&quot;</span>
<span class="token key attr-name">-Dspark.history.ui.port</span><span class="token punctuation">=</span><span class="token value attr-value">18080</span>
<span class="token key attr-name">-Dspark.history.retainedApplications</span><span class="token punctuation">=</span><span class="token value attr-value">30</span>
<span class="token key attr-name">-Dspark.history.fs.logDirectory</span><span class="token punctuation">=</span><span class="token value attr-value">hdfs://hadoop01:9000/directory&quot;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>参数描述：</p> <ul><li><p>spark.eventLog.dir：Application在运行过程中所有的信息均记录在该属性指定的路径下</p></li> <li><p>spark.history.ui.port=18080  WEBUI访问的端口号为18080</p></li> <li><p>spark.history.fs.logDirectory=hdfs://hadoop102:9000/directory配置了该属性后，在start-history-server.sh时就无需再显式的指定路径，Spark History Server页面只展示该指定路径下的信息</p></li> <li><p>spark.history.retainedApplications=30指定保存Application历史记录的个数，如果超过这个值，旧的应用程序信息将被删除，这个是内存中的应用数，而不是页面上显示的应用数。</p></li></ul> <p>4）分发配置文件</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@hadoop01 conf<span class="token punctuation">]</span><span class="token comment"># xsync spark-defaults.conf</span>
<span class="token punctuation">[</span>root@hadoop01 conf<span class="token punctuation">]</span><span class="token comment"># xsync spark-env.sh</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>5）启动历史服务</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@hadoop01 spark<span class="token punctuation">]</span><span class="token comment"># sbin/start-history-server.sh</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>6）再次执行任务</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@hadoop01 spark<span class="token punctuation">]</span><span class="token comment"># bin/spark-submit \</span>
<span class="token parameter variable">--class</span> org.apache.spark.examples.SparkPi <span class="token punctuation">\</span>
<span class="token parameter variable">--master</span> spark://hadoop01:7077 <span class="token punctuation">\</span>
--executor-memory 1G <span class="token punctuation">\</span>
--total-executor-cores <span class="token number">2</span> <span class="token punctuation">\</span>
./examples/jars/spark-examples_2.11-2.1.1.jar <span class="token punctuation">\</span>
<span class="token number">100</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>7）查看历史服务</p> <p>hadoop01:18080</p> <p><img src="/assets/img/image-20230721130626873.235a6b07.png" alt="image-20230721130626873"></p> <h4 id="_2-4-4-ha配置"><a href="#_2-4-4-ha配置" class="header-anchor">#</a> 2.4.4 HA配置</h4> <p><img src="/assets/img/HA架构图.6ada81ee.png" alt="image-20230721130652708"></p> <p>1）zookeeper正常安装并启动(安装步骤见Zookeeper篇)</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@hadoop01 spark<span class="token punctuation">]</span><span class="token comment"># /opt/module/zookeeper-3.4.10/bin/zkServer.sh start</span>

<span class="token punctuation">[</span>root@hadoop02 spark<span class="token punctuation">]</span><span class="token comment"># /opt/module/zookeeper-3.4.10/bin/zkServer.sh start</span>

<span class="token punctuation">[</span>root@hadoop03 spark<span class="token punctuation">]</span><span class="token comment"># /opt/module/zookeeper-3.4.10/bin/zkServer.sh start</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>2）修改spark-env.sh文件添加如下配置：</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@hadoop01 conf<span class="token punctuation">]</span><span class="token comment"># vi spark-env.sh</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>注释掉如下内容：(上文2.4.2节曾配置过)</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>#SPARK_MASTER_HOST=hadoop01
#SPARK_MASTER_PORT=7077
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>添加上如下内容：</p> <div class="language-properties line-numbers-mode"><pre class="language-properties"><code><span class="token key attr-name">export</span> <span class="token value attr-value">SPARK_DAEMON_JAVA_OPTS=&quot;</span>
<span class="token key attr-name">-Dspark.deploy.recoveryMode</span><span class="token punctuation">=</span><span class="token value attr-value">ZOOKEEPER</span>
<span class="token key attr-name">-Dspark.deploy.zookeeper.url</span><span class="token punctuation">=</span><span class="token value attr-value">hadoop01,hadoop02,hadoop03</span>
<span class="token key attr-name">-Dspark.deploy.zookeeper.dir</span><span class="token punctuation">=</span><span class="token value attr-value">/spark&quot;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>3）分发配置文件</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@hadoop01 conf<span class="token punctuation">]</span><span class="token comment"># xsync spark-env.sh</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>4）在hadoop01上启动全部节点，此时hadoop01作为Active的Master节点</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@hadoop01 spark<span class="token punctuation">]</span><span class="token comment"># sbin/start-all.sh</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>5）在hadoop02上单独启动master节点，此时hadoop02作为STANDBY的Master</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@hadoop01 spark<span class="token punctuation">]</span><span class="token comment"># sbin/start-master.sh</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>6）spark HA集群访问</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code>/opt/module/spark/bin/spark-shell <span class="token punctuation">\</span>
<span class="token parameter variable">--master</span> spark://hadoop01:7077,hadoop02:7077 <span class="token punctuation">\</span>
--executor-memory 2g <span class="token punctuation">\</span>
--total-executor-cores <span class="token number">2</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><h3 id="_2-5-yarn模式"><a href="#_2-5-yarn模式" class="header-anchor">#</a> 2.5 Yarn模式</h3> <h4 id="_2-5-1-概述"><a href="#_2-5-1-概述" class="header-anchor">#</a> 2.5.1 概述</h4> <p>Spark客户端直接连接Yarn，不需要额外构建Spark集群。有yarn-client和yarn-cluster两种模式，主要区别在于：Driver程序的运行节点。</p> <p>yarn-client：Driver程序运行在客户端，适用于交互、调试，希望立即看到app的输出</p> <p>yarn-cluster：Driver程序运行在由RM（ResourceManager）启动的AM（APPMaster）适用于生产环境。</p> <p><img src="/assets/img/Yarn运行模式.cb4d3b8b.png" alt="img"></p> <h4 id="_2-5-2-安装使用"><a href="#_2-5-2-安装使用" class="header-anchor">#</a> 2.5.2 安装使用</h4> <p>1）修改/opt/module/hadoop-2.7.2/etc/hadoop配置文件yarn-site.xml,添加如下内容：</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@hadoop01 hadoop<span class="token punctuation">]</span><span class="token comment"># vi yarn-site.xml</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><div class="language-xml line-numbers-mode"><pre class="language-xml"><code><span class="token comment">&lt;!--是否启动一个线程检查每个任务正使用的物理内存量，如果任务超出分配值，则直接将其杀掉，默认是true --&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.nodemanager.pmem-check-enabled<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token comment">&lt;!--是否启动一个线程检查每个任务正使用的虚拟内存量，如果任务超出分配值，则直接将其杀掉，默认是true --&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.nodemanager.vmem-check-enabled<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><p>2）修改spark-env.sh，添加如下配置：</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@hadoop01 conf<span class="token punctuation">]</span><span class="token comment"># vi spark-env.sh</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><div class="language- line-numbers-mode"><pre class="language-text"><code>YARN_CONF_DIR=/opt/module/hadoop-2.7.2/etc/hadoop
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>3）分发配置文件</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@hadoop01 conf<span class="token punctuation">]</span><span class="token comment"># xsync /opt/module/hadoop-2.7.2/etc/hadoop/yarn-site.xml</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>4）执行一个程序</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@hadoop01 spark<span class="token punctuation">]</span><span class="token comment"># bin/spark-submit \</span>
<span class="token parameter variable">--class</span> org.apache.spark.examples.SparkPi <span class="token punctuation">\</span>
<span class="token parameter variable">--master</span> <span class="token function">yarn</span> <span class="token punctuation">\</span>
--deploy-mode client <span class="token punctuation">\</span>
./examples/jars/spark-examples_2.11-2.1.1.jar <span class="token punctuation">\</span>
<span class="token number">100</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><div class="language- line-numbers-mode"><pre class="language-text"><code>Pi is roughly 3.1418247141824716
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>注意：在提交任务之前需启动HDFS以及YARN集群。</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@hadoop01 spark<span class="token punctuation">]</span><span class="token comment"># /opt/module/hadoop-2.7.2/sbin/stop-dfs.sh</span>
<span class="token punctuation">[</span>root@hadoop02 spark<span class="token punctuation">]</span><span class="token comment"># /opt/module/hadoop-2.7.2/sbin/stop-yarn.sh</span>

<span class="token punctuation">[</span>root@hadoop01 spark<span class="token punctuation">]</span><span class="token comment"># /opt/module/hadoop-2.7.2/sbin/start-dfs.sh</span>
<span class="token punctuation">[</span>root@hadoop02 spark<span class="token punctuation">]</span><span class="token comment"># /opt/module/hadoop-2.7.2/sbin/start-yarn.sh</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><h4 id="_2-5-3-日志查看"><a href="#_2-5-3-日志查看" class="header-anchor">#</a> 2.5.3 日志查看</h4> <p>1）修改配置文件spark-defaults.conf</p> <p>添加如下内容：</p> <div class="language-properties line-numbers-mode"><pre class="language-properties"><code><span class="token key attr-name">spark.yarn.historyServer.address</span><span class="token punctuation">=</span><span class="token value attr-value">hadoop01:18080</span>
<span class="token key attr-name">spark.history.ui.port</span><span class="token punctuation">=</span><span class="token value attr-value">18080</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>2）重启spark历史服务</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@hadoop01 spark<span class="token punctuation">]</span><span class="token comment"># sbin/stop-history-server.sh</span>
<span class="token punctuation">[</span>root@hadoop01 spark<span class="token punctuation">]</span><span class="token comment"># sbin/start-history-server.sh</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>3）提交任务到Yarn执行</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@hadoop01 spark<span class="token punctuation">]</span><span class="token comment"># bin/spark-submit \</span>
<span class="token parameter variable">--class</span> org.apache.spark.examples.SparkPi <span class="token punctuation">\</span>
<span class="token parameter variable">--master</span> <span class="token function">yarn</span> <span class="token punctuation">\</span>
--deploy-mode client <span class="token punctuation">\</span>
./examples/jars/spark-examples_2.11-2.1.1.jar <span class="token punctuation">\</span>
<span class="token number">100</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><div class="language- line-numbers-mode"><pre class="language-text"><code>Pi is roughly 3.1415075141507516
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>4）Web页面查看日志</p> <p><img src="/assets/img/image-20230721153035336.63254e4c.png" alt="image-20230721153035336"></p> <h3 id="_2-6-mesos模式"><a href="#_2-6-mesos模式" class="header-anchor">#</a> 2.6 Mesos模式</h3> <p>Spark客户端直接连接Mesos；不需要额外构建Spark集群。国内应用比较少，更多的是运用yarn调度。</p> <h3 id="_2-7-几种模式对比"><a href="#_2-7-几种模式对比" class="header-anchor">#</a> 2.7 几种模式对比</h3> <table><thead><tr><th>模式</th> <th>Spark安装机器数</th> <th>需启动的进程</th> <th>所属者</th></tr></thead> <tbody><tr><td>Local</td> <td>1</td> <td>无</td> <td>Spark</td></tr> <tr><td>Standalone</td> <td>3</td> <td>Master及Worker</td> <td>Spark</td></tr> <tr><td>Yarn</td> <td>1</td> <td>Yarn及HDFS</td> <td>Hadoop</td></tr></tbody></table> <h2 id="第3章-案例实操"><a href="#第3章-案例实操" class="header-anchor">#</a> 第3章 案例实操</h2> <p>Spark Shell仅在测试和验证我们的程序时使用的较多，在生产环境中，通常会在IDE中编制程序，然后打成jar包，然后提交到集群，最常用的是创建一个Maven项目，利用Maven来管理jar包的依赖。</p> <h3 id="_3-1-编写wordcount程序"><a href="#_3-1-编写wordcount程序" class="header-anchor">#</a> 3.1 编写WordCount程序</h3> <p>1）创建一个Maven项目WordCount并导入依赖</p> <div class="language-xml line-numbers-mode"><pre class="language-xml"><code><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>spark-core_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>2.1.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">&gt;</span></span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>2）编写代码</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>root</span>  
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>  
<span class="token keyword">object</span> WordCount<span class="token punctuation">{</span>  
    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>

        <span class="token comment">//1.创建SparkConf并设置App名称  </span>
        <span class="token keyword">val</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;WC&quot;</span><span class="token punctuation">)</span>

        <span class="token comment">//2.创建SparkContext，该对象是提交Spark App的入口  </span>
        <span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>  

        <span class="token comment">//3.使用sc创建RDD并执行相应的transformation和action  </span>
        sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span>args<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>\_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>\_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>\_<span class="token operator">+</span>\_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sortBy<span class="token punctuation">(</span>\_<span class="token punctuation">.</span>\_2<span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">.</span>saveAsTextFile<span class="token punctuation">(</span>args<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment">//4.关闭连接  </span>
        sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>  
	<span class="token punctuation">}</span>  
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br></div></div><p>3）打包插件</p> <div class="language-xml line-numbers-mode"><pre class="language-xml"><code><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>build</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>finalName</span><span class="token punctuation">&gt;</span></span>WordCount<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>finalName</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugins</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.maven.plugins<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>maven-assembly-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>archive</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>manifest</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>mainClass</span><span class="token punctuation">&gt;</span></span>com.saint.spark.WordCount<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>mainClass</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>manifest</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>archive</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>descriptorRefs</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>descriptorRef</span><span class="token punctuation">&gt;</span></span>jar-with-dependencies<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>descriptorRef</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>descriptorRefs</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>executions</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>execution</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">&gt;</span></span>make-assembly<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>phase</span><span class="token punctuation">&gt;</span></span>package<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>phase</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goals</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">&gt;</span></span>single<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goals</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>execution</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>executions</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugins</span><span class="token punctuation">&gt;</span></span>
   	<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>build</span><span class="token punctuation">&gt;</span></span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br></div></div><p>4）打包到集群测试</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code>bin/spark-submit <span class="token punctuation">\</span>
<span class="token parameter variable">--class</span> com.saint.spark.WordCount <span class="token punctuation">\</span>
<span class="token parameter variable">--master</span> spark://hadoop02:7077 <span class="token punctuation">\</span>
/opt/module/jars/WordCount-jar-with-dependencies.jar <span class="token punctuation">\</span>
hdfs://hadoop01:9000/t.txt hdfs://hadoop01:9000/sparkTest.txt
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><h3 id="_3-2-本地调试"><a href="#_3-2-本地调试" class="header-anchor">#</a> 3.2 本地调试</h3> <p>本地Spark程序调试需要使用local提交模式，即将本机当做运行环境，Master和Worker都为本机。运行时直接加断点调试即可。如下：</p> <p>创建SparkConf的时候设置额外属性，表明本地执行：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>val conf = new SparkConf().setAppName(&quot;WC&quot;).setMaster(&quot;local[*]&quot;)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>如果本机操作系统是windows，如果在程序中使用了hadoop相关的东西，比如写入文件到HDFS，则会遇到如下异常：</p> <p><img src="/assets/img/image-20230721161726188.98e0baff.png" alt="image-20230721161726188"></p> <p>出现这个问题的原因，并不是程序的错误，而是用到了hadoop相关的服务，解决办法是将附加里面的hadoop-common-bin-2.7.3-x64.zip解压到任意目录。</p> <p>在IDEA中配置Run Configuration，添加HADOOP_HOME变量</p></div></section> <footer class="page-edit"><!----> <!----></footer> <!----> <div class="comments-wrapper"><!----></div></main></div> <!----></div> <ul class="sub-sidebar sub-sidebar-wrapper" style="width:12rem;" data-v-b57cc07c data-v-7dd95ae2><li class="level-2" data-v-b57cc07c><a href="/blogs/BigData/Spark/Spark%E5%9F%BA%E7%A1%80.html#第1章-spark概述" class="sidebar-link reco-side-第1章-spark概述" data-v-b57cc07c>第1章 Spark概述</a></li><li class="level-3" data-v-b57cc07c><a href="/blogs/BigData/Spark/Spark%E5%9F%BA%E7%A1%80.html#_1-1-什么是spark" class="sidebar-link reco-side-_1-1-什么是spark" data-v-b57cc07c>1.1 什么是Spark</a></li><li class="level-3" data-v-b57cc07c><a href="/blogs/BigData/Spark/Spark%E5%9F%BA%E7%A1%80.html#_1-2-spark内置模块" class="sidebar-link reco-side-_1-2-spark内置模块" data-v-b57cc07c>1.2 Spark内置模块</a></li><li class="level-3" data-v-b57cc07c><a href="/blogs/BigData/Spark/Spark%E5%9F%BA%E7%A1%80.html#_1-3-spark特点" class="sidebar-link reco-side-_1-3-spark特点" data-v-b57cc07c>1.3 Spark特点</a></li><li class="level-2" data-v-b57cc07c><a href="/blogs/BigData/Spark/Spark%E5%9F%BA%E7%A1%80.html#第2章-spark运行模式" class="sidebar-link reco-side-第2章-spark运行模式" data-v-b57cc07c>第2章 Spark运行模式</a></li><li class="level-3" data-v-b57cc07c><a href="/blogs/BigData/Spark/Spark%E5%9F%BA%E7%A1%80.html#_2-1-spark安装地址" class="sidebar-link reco-side-_2-1-spark安装地址" data-v-b57cc07c>2.1 Spark安装地址</a></li><li class="level-3" data-v-b57cc07c><a href="/blogs/BigData/Spark/Spark%E5%9F%BA%E7%A1%80.html#_2-3-local模式" class="sidebar-link reco-side-_2-3-local模式" data-v-b57cc07c>2.3 Local模式</a></li><li class="level-3" data-v-b57cc07c><a href="/blogs/BigData/Spark/Spark%E5%9F%BA%E7%A1%80.html#_2-4-standalone模式" class="sidebar-link reco-side-_2-4-standalone模式" data-v-b57cc07c>2.4 Standalone模式</a></li><li class="level-3" data-v-b57cc07c><a href="/blogs/BigData/Spark/Spark%E5%9F%BA%E7%A1%80.html#_2-5-yarn模式" class="sidebar-link reco-side-_2-5-yarn模式" data-v-b57cc07c>2.5 Yarn模式</a></li><li class="level-3" data-v-b57cc07c><a href="/blogs/BigData/Spark/Spark%E5%9F%BA%E7%A1%80.html#_2-6-mesos模式" class="sidebar-link reco-side-_2-6-mesos模式" data-v-b57cc07c>2.6 Mesos模式</a></li><li class="level-3" data-v-b57cc07c><a href="/blogs/BigData/Spark/Spark%E5%9F%BA%E7%A1%80.html#_2-7-几种模式对比" class="sidebar-link reco-side-_2-7-几种模式对比" data-v-b57cc07c>2.7 几种模式对比</a></li><li class="level-2" data-v-b57cc07c><a href="/blogs/BigData/Spark/Spark%E5%9F%BA%E7%A1%80.html#第3章-案例实操" class="sidebar-link reco-side-第3章-案例实操" data-v-b57cc07c>第3章 案例实操</a></li><li class="level-3" data-v-b57cc07c><a href="/blogs/BigData/Spark/Spark%E5%9F%BA%E7%A1%80.html#_3-1-编写wordcount程序" class="sidebar-link reco-side-_3-1-编写wordcount程序" data-v-b57cc07c>3.1 编写WordCount程序</a></li><li class="level-3" data-v-b57cc07c><a href="/blogs/BigData/Spark/Spark%E5%9F%BA%E7%A1%80.html#_3-2-本地调试" class="sidebar-link reco-side-_3-2-本地调试" data-v-b57cc07c>3.2 本地调试</a></li></ul></div></div></div><div class="global-ui"><div class="back-to-ceiling" style="right:1rem;bottom:6rem;width:2.5rem;height:2.5rem;border-radius:.25rem;line-height:2.5rem;display:none;" data-v-c6073ba8 data-v-c6073ba8><svg t="1574745035067" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="5404" class="icon" data-v-c6073ba8><path d="M526.60727968 10.90185116a27.675 27.675 0 0 0-29.21455937 0c-131.36607665 82.28402758-218.69155461 228.01873535-218.69155402 394.07834331a462.20625001 462.20625001 0 0 0 5.36959153 69.94390903c1.00431239 6.55289093-0.34802892 13.13561351-3.76865779 18.80351572-32.63518765 54.11355614-51.75690182 118.55860487-51.7569018 187.94566865a371.06718723 371.06718723 0 0 0 11.50484808 91.98906777c6.53300375 25.50556257 41.68394495 28.14064038 52.69160883 4.22606766 17.37162448-37.73630017 42.14135425-72.50938081 72.80769204-103.21549295 2.18761121 3.04276886 4.15646224 6.24463696 6.40373557 9.22774369a1871.4375 1871.4375 0 0 0 140.04691725 5.34970492 1866.36093723 1866.36093723 0 0 0 140.04691723-5.34970492c2.24727335-2.98310674 4.21612437-6.18497483 6.3937923-9.2178004 30.66633723 30.70611158 55.4360664 65.4791928 72.80769147 103.21549355 11.00766384 23.91457269 46.15860503 21.27949489 52.69160879-4.22606768a371.15156223 371.15156223 0 0 0 11.514792-91.99901164c0-69.36717486-19.13165746-133.82216804-51.75690182-187.92578088-3.42062944-5.66790279-4.76302748-12.26056868-3.76865837-18.80351632a462.20625001 462.20625001 0 0 0 5.36959269-69.943909c-0.00994388-166.08943902-87.32547796-311.81420293-218.6915546-394.09823051zM605.93803103 357.87693858a93.93749974 93.93749974 0 1 1-187.89594924 6.1e-7 93.93749974 93.93749974 0 0 1 187.89594924-6.1e-7z" p-id="5405" data-v-c6073ba8></path><path d="M429.50777625 765.63860547C429.50777625 803.39355007 466.44236686 1000.39046097 512.00932183 1000.39046097c45.56695499 0 82.4922232-197.00623328 82.5015456-234.7518555 0-37.75494459-36.9345906-68.35043303-82.4922232-68.34111062-45.57627738-0.00932239-82.52019037 30.59548842-82.51086798 68.34111062z" p-id="5406" data-v-c6073ba8></path></svg></div><!----><div class="RibbonAnimation"></div><div></div></div></div>
    <script src="/assets/js/app.4c955a77.js" defer></script><script src="/assets/js/4.1f64e010.js" defer></script><script src="/assets/js/1.2b09ee83.js" defer></script><script src="/assets/js/9.30f2afa9.js" defer></script>
  </body>
</html>
